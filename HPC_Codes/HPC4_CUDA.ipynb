{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDLPWN-JsGe8",
        "outputId": "9cdc0465-67ce-482c-dd31-83f027de630c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue May  6 05:36:29 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile vector_add.cu\n",
        "#include <iostream>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "\n",
        "using namespace std;\n",
        "using namespace std::chrono;\n",
        "\n",
        "// CUDA kernel\n",
        "__global__ void vectorAdd(int* A, int* B, int* C, int n) {\n",
        "    int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (i < n) {\n",
        "        C[i] = A[i] + B[i];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int n;\n",
        "    cout << \"Enter size of vectors: \";\n",
        "    cin >> n;\n",
        "\n",
        "    size_t size = n * sizeof(int);\n",
        "\n",
        "    // Host memory\n",
        "    int* h_A = (int*)malloc(size);\n",
        "    int* h_B = (int*)malloc(size);\n",
        "    int* h_C = (int*)malloc(size);\n",
        "\n",
        "    cout << \"Enter elements for Vector A:\\n\";\n",
        "    for (int i = 0; i < n; i++) cin >> h_A[i];\n",
        "\n",
        "    cout << \"Enter elements for Vector B:\\n\";\n",
        "    for (int i = 0; i < n; i++) cin >> h_B[i];\n",
        "\n",
        "    // Device memory\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    cudaMalloc((void**)&d_A, size);\n",
        "    cudaMalloc((void**)&d_B, size);\n",
        "    cudaMalloc((void**)&d_C, size);\n",
        "\n",
        "    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    auto start = high_resolution_clock::now();\n",
        "    vectorAdd<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, n);\n",
        "    cudaDeviceSynchronize();\n",
        "    auto end = high_resolution_clock::now();\n",
        "\n",
        "    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    cout << \"\\nVector Addition Result (first 10 elements):\\n\";\n",
        "    for (int i = 0; i < min(n, 10); i++) {\n",
        "        cout << h_A[i] << \" + \" << h_B[i] << \" = \" << h_C[i] << endl;\n",
        "    }\n",
        "\n",
        "    auto duration = duration_cast<milliseconds>(end - start);\n",
        "    cout << \"\\nTime taken by GPU (in milliseconds): \" << duration.count() << \" ms\" << endl;\n",
        "\n",
        "    // Free memory\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    free(h_A); free(h_B); free(h_C);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AZIeC72spTU",
        "outputId": "bb4ca462-2d97-451a-8b27-fd038da77591"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting vector_add.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 vector_add.cu -o vector_add"
      ],
      "metadata": {
        "id": "t4QuHzGfs0Re"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./vector_add"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adNtDcAps4aT",
        "outputId": "2635f393-6c5d-4b40-f3ad-5f8c3e73d5bb"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter size of vectors: 3\n",
            "Enter elements for Vector A:\n",
            "1\n",
            "2\n",
            "3\n",
            "Enter elements for Vector B:\n",
            "4\n",
            "5\n",
            "6\n",
            "\n",
            "Vector Addition Result (first 10 elements):\n",
            "1 + 4 = 5\n",
            "2 + 5 = 7\n",
            "3 + 6 = 9\n",
            "\n",
            "Time taken by GPU (in milliseconds): 0 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile matrix_multiplication.cu\n",
        "\n",
        "#include <iostream>\n",
        "#include <cstdlib>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "using namespace std;\n",
        "using namespace chrono;\n",
        "\n",
        "// CUDA kernel to multiply matrices A and B into C\n",
        "__global__ void matrixMulKernel(int* A, int* B, int* C, int M, int N, int P) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y; // Row of C\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x; // Column of C\n",
        "\n",
        "    if (row < M && col < P) {\n",
        "        int sum = 0;\n",
        "        for (int k = 0; k < N; ++k) {\n",
        "            sum += A[row * N + k] * B[k * P + col];\n",
        "        }\n",
        "        C[row * P + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int M, N, P;\n",
        "    cout << \"Enter dimensions of Matrix A (MxN):\\n\";\n",
        "    cin >> M >> N;\n",
        "    cout << \"Enter number of columns for Matrix B (NxP):\\n\";\n",
        "    cin >> P;\n",
        "\n",
        "    int *h_A = new int[M * N];\n",
        "    int *h_B = new int[N * P];\n",
        "    int *h_C = new int[M * P];\n",
        "\n",
        "    // Take input from user\n",
        "    cout << \"Enter elements of Matrix A (\" << M << \"x\" << N << \"):\\n\";\n",
        "    for (int i = 0; i < M * N; i++)\n",
        "        cin >> h_A[i];\n",
        "\n",
        "    cout << \"Enter elements of Matrix B (\" << N << \"x\" << P << \"):\\n\";\n",
        "    for (int i = 0; i < N * P; i++)\n",
        "        cin >> h_B[i];\n",
        "\n",
        "    // Allocate device memory\n",
        "    int *d_A, *d_B, *d_C;\n",
        "    size_t size_A = M * N * sizeof(int);\n",
        "    size_t size_B = N * P * sizeof(int);\n",
        "    size_t size_C = M * P * sizeof(int);\n",
        "\n",
        "    cudaMalloc((void**)&d_A, size_A);\n",
        "    cudaMalloc((void**)&d_B, size_B);\n",
        "    cudaMalloc((void**)&d_C, size_C);\n",
        "\n",
        "    // Copy data to device\n",
        "    cudaMemcpy(d_A, h_A, size_A, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_B, h_B, size_B, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define block and grid dimensions\n",
        "    dim3 threadsPerBlock(16, 16); // 256 threads per block\n",
        "    dim3 blocksPerGrid((P + 15) / 16, (M + 15) / 16);\n",
        "\n",
        "    // Measure time\n",
        "    auto start = high_resolution_clock::now();\n",
        "\n",
        "    // Launch the CUDA kernel\n",
        "    matrixMulKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_B, d_C, M, N, P);\n",
        "\n",
        "    cudaDeviceSynchronize(); // Wait for GPU to finish\n",
        "\n",
        "    auto end = high_resolution_clock::now();\n",
        "    auto duration = duration_cast<microseconds>(end - start);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_C, d_C, size_C, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Display result\n",
        "    cout << \"\\nResultant Matrix C (\" << M << \"x\" << P << \"):\\n\";\n",
        "    for (int i = 0; i < M; i++) {\n",
        "        for (int j = 0; j < P; j++) {\n",
        "            cout << h_C[i * P + j] << \"\\t\";\n",
        "        }\n",
        "        cout << \"\\n\";\n",
        "    }\n",
        "\n",
        "    cout << \"\\nTime taken by GPU: \" << duration.count() << \" microseconds\\n\";\n",
        "\n",
        "    // Thread information\n",
        "    cout << \"Threads per Block: \" << threadsPerBlock.x * threadsPerBlock.y << \"\\n\";\n",
        "    cout << \"Total Threads (approx): \" << blocksPerGrid.x * blocksPerGrid.y * threadsPerBlock.x * threadsPerBlock.y << \"\\n\";\n",
        "\n",
        "    // Cleanup\n",
        "    cudaFree(d_A); cudaFree(d_B); cudaFree(d_C);\n",
        "    delete[] h_A; delete[] h_B; delete[] h_C;\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6hhscG-zHvp",
        "outputId": "8da013e9-3b18-470c-a8f4-20d71a33a4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing matrix_multiplication.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 matrix_multiplication.cu -o matrix_multiplication"
      ],
      "metadata": {
        "id": "_9mYM2WnzN-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./matrix_multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xwfd-BGlzoVH",
        "outputId": "bb14d8ad-9a66-43b0-d3ad-b92d50b86922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter dimensions of Matrix A (MxN):\n",
            "3 3\n",
            "Enter number of columns for Matrix B (NxP):\n",
            "3\n",
            "Enter elements of Matrix A (3x3):\n",
            "1 2 3\n",
            "4 5 6\n",
            "7 8 9\n",
            "Enter elements of Matrix B (3x3):\n",
            "9 8 7\n",
            "6 5 4\n",
            "3 2 1\n",
            "\n",
            "Resultant Matrix C (3x3):\n",
            "30\t24\t18\t\n",
            "84\t69\t54\t\n",
            "138\t114\t90\t\n",
            "\n",
            "Time taken by GPU: 148 microseconds\n",
            "Threads per Block: 256\n",
            "Total Threads (approx): 256\n"
          ]
        }
      ]
    }
  ]
}